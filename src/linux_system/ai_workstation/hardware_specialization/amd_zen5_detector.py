"""
AMD Zen 5 Workload Detector

Specialized monitoring and optimization intelligence for AMD Ryzen 9950X
Zen 5 architecture, providing advanced CPU performance analysis, AOCL library
utilization tracking, and AI workload optimization specific to Zen 5 features.

Features:
- Zen 5 performance counter monitoring and analysis
- AOCL (AMD Optimized CPU Libraries) utilization tracking
- DDR5-6000 memory bandwidth optimization monitoring
- Core pinning effectiveness analysis for AI containers
- NUMA topology optimization insights
- Power management and efficiency tracking
- Cache hierarchy utilization analysis
- AI workload pattern recognition and optimization
"""

import os
import re
import subprocess
import psutil
import logging
import threading
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Set
from dataclasses import dataclass, field
from collections import defaultdict, deque
from pathlib import Path
import json

from ...temporal.core.change_detector import SystemChangeDetector, SystemState, SystemChange
from ...temporal.core.types import ChangeType, ComponentType, Significance


logger = logging.getLogger(__name__)


@dataclass
class Zen5PerformanceCounters:
    """Zen 5 architecture performance counters."""
    timestamp: datetime
    
    # Core utilization per container
    llama_cpu_0_utilization: float  # Cores 0-7
    llama_cpu_1_utilization: float  # Cores 8-15
    llama_cpu_2_utilization: float  # Cores 16-23
    system_utilization: float       # Overall system
    
    # Performance counters
    instructions_per_sec: float
    cycles_per_sec: float
    ipc: float  # Instructions per cycle
    cache_misses_per_sec: float
    branch_mispredictions_per_sec: float
    
    # Memory performance
    memory_bandwidth_utilization: float  # % of DDR5-6000 bandwidth
    numa_local_access_ratio: float       # NUMA locality efficiency
    memory_latency_ns: float
    
    # AI workload specific
    vectorized_operations_per_sec: float
    aocl_library_utilization: float
    mathematical_throughput: float
    
    # Power and thermal
    package_power_watts: float
    core_temperatures: List[float]  # Per-core temperatures
    power_efficiency_score: float
    
    # Cache hierarchy
    l1_cache_hit_rate: float
    l2_cache_hit_rate: float
    l3_cache_hit_rate: float
    cache_bandwidth_utilization: float


@dataclass
class AOCLLibraryUsage:
    """AOCL (AMD Optimized CPU Libraries) usage analysis."""
    blis_operations_per_sec: float
    lapack_operations_per_sec: float
    fftw_operations_per_sec: float
    scalapack_operations_per_sec: float
    optimization_level: str  # none, basic, advanced
    performance_gain_estimate: float  # vs generic libraries


@dataclass
class CorePinningAnalysis:
    """Analysis of core pinning effectiveness for AI containers."""
    container_name: str
    assigned_cores: List[int]
    actual_core_usage: Dict[int, float]  # Core ID -> utilization %
    pinning_effectiveness: float  # 0-1, how well pinning is working
    cross_numa_access_ratio: float
    performance_impact: str  # positive, negative, neutral
    optimization_recommendations: List[str]


@dataclass
class Zen5WorkloadProfile:
    """AI workload profile for Zen 5 optimization."""
    workload_id: str
    workload_type: str  # cpu_inference, mathematical, mixed
    compute_intensity: str  # integer, floating_point, vectorized
    memory_access_pattern: str  # sequential, random, streaming
    cache_efficiency: float
    numa_affinity: int  # Preferred NUMA node
    aocl_optimization_potential: float
    recommended_optimizations: List[str]


class AMDZen5WorkloadDetector(SystemChangeDetector):
    """
    Advanced detector for AMD Zen 5 architecture workload optimization.
    
    Provides specialized monitoring and intelligent analysis of Zen 5
    performance characteristics, AOCL library utilization, and AI workload
    optimization opportunities specific to the Ryzen 9950X architecture.
    """
    
    def __init__(self, monitoring_interval: float = 10.0):
        super().__init__()
        self.monitoring_interval = monitoring_interval
        
        # Zen 5 architecture configuration
        self.zen5_config = {
            'cpu_model': 'AMD Ryzen 9 9950X',
            'architecture': 'Zen 5',
            'total_cores': 16,
            'total_threads': 32,
            'base_clock_ghz': 4.3,
            'boost_clock_ghz': 5.7,
            'l1_cache_kb': 64,     # Per core
            'l2_cache_kb': 1024,   # Per core  
            'l3_cache_mb': 64,     # Shared
            'memory_channels': 2,
            'memory_type': 'DDR5-6000',
            'memory_bandwidth_gbps': 95.37,  # Theoretical peak
            'numa_nodes': 2
        }
        
        # Container core assignments (from docker-compose)
        self.container_cores = {
            'llama-cpu-0': list(range(0, 8)),   # Cores 0-7
            'llama-cpu-1': list(range(8, 16)),  # Cores 8-15
            'llama-cpu-2': list(range(16, 24))  # Cores 16-23 (note: only 16 cores total)
        }
        
        # Adjust for actual core count
        self.container_cores['llama-cpu-2'] = list(range(16, min(24, self.zen5_config['total_cores'])))
        
        # Performance monitoring state
        self.previous_counters: Optional[Zen5PerformanceCounters] = None
        self.performance_history: deque = deque(maxlen=500)
        self.workload_profiles: Dict[str, Zen5WorkloadProfile] = {}
        self.core_pinning_analysis: Dict[str, CorePinningAnalysis] = {}
        
        # AOCL library monitoring
        self.aocl_libraries = {
            'libblis.so': 'BLAS operations',
            'liblapack.so': 'Linear algebra',
            'libfftw3.so': 'FFT operations',
            'libscalapack.so': 'Parallel linear algebra'
        }
        self.aocl_usage_history: deque = deque(maxlen=200)
        
        # Background monitoring
        self.monitoring_active = False
        self.monitor_thread: Optional[threading.Thread] = None
        
        # Change detection thresholds
        self.change_thresholds = {
            'cpu_utilization': 15.0,   # % change per container
            'ipc_change': 0.2,          # Instructions per cycle change
            'memory_bandwidth': 10.0,   # % bandwidth change
            'cache_hit_rate': 5.0,      # % hit rate change
            'power_consumption': 20.0,  # W change
            'temperature': 10.0,        # Â°C change
            'aocl_utilization': 10.0    # % AOCL usage change
        }
        
        # Initialize system information
        self.cpu_info = self._get_cpu_info()
        self.numa_topology = self._analyze_numa_topology()
        
        # Performance counter initialization
        self.perf_available = self._check_perf_availability()
        if not self.perf_available:
            logger.warning("Linux perf not available - some metrics will be estimated")
            
    def _get_cpu_info(self) -> Dict[str, Any]:
        """Get detailed CPU information for Zen 5 verification."""
        cpu_info = {}
        
        try:
            # Read CPU info from /proc/cpuinfo
            with open('/proc/cpuinfo', 'r') as f:
                cpuinfo = f.read()
                
            # Extract key information
            cpu_info['model_name'] = re.search(r'model name\s*:\s*(.+)', cpuinfo)
            cpu_info['model_name'] = cpu_info['model_name'].group(1) if cpu_info['model_name'] else 'Unknown'
            
            cpu_info['cpu_cores'] = re.search(r'cpu cores\s*:\s*(\d+)', cpuinfo)
            cpu_info['cpu_cores'] = int(cpu_info['cpu_cores'].group(1)) if cpu_info['cpu_cores'] else 0
            
            cpu_info['siblings'] = re.search(r'siblings\s*:\s*(\d+)', cpuinfo)
            cpu_info['siblings'] = int(cpu_info['siblings'].group(1)) if cpu_info['siblings'] else 0
            
            # Verify Zen 5 architecture
            cpu_info['is_zen5'] = 'Zen 5' in cpu_info['model_name'] or '9950X' in cpu_info['model_name']
            
            logger.info(f"Detected CPU: {cpu_info['model_name']}, Zen 5: {cpu_info['is_zen5']}")
            
        except Exception as e:
            logger.error(f"Error reading CPU info: {e}")
            cpu_info['model_name'] = 'Unknown'
            cpu_info['is_zen5'] = False
            
        return cpu_info
        
    def _analyze_numa_topology(self) -> Dict[str, Any]:
        """Analyze NUMA topology for optimization insights."""
        numa_info = {
            'nodes': [],
            'node_cpu_map': {},
            'distances': {}
        }
        
        try:
            # Check if NUMA is available
            numa_nodes_path = Path('/sys/devices/system/node')
            if not numa_nodes_path.exists():
                logger.info("NUMA topology not available")
                return numa_info
                
            # Get NUMA nodes
            for node_dir in numa_nodes_path.glob('node*'):
                if node_dir.is_dir():
                    node_id = int(node_dir.name[4:])  # Extract number from 'nodeX'
                    numa_info['nodes'].append(node_id)
                    
                    # Get CPUs for this node
                    cpulist_file = node_dir / 'cpulist'
                    if cpulist_file.exists():
                        with open(cpulist_file, 'r') as f:
                            cpu_range = f.read().strip()
                            cpus = self._parse_cpu_range(cpu_range)
                            numa_info['node_cpu_map'][node_id] = cpus
                            
            logger.info(f"NUMA topology: {len(numa_info['nodes'])} nodes, CPU mapping: {numa_info['node_cpu_map']}")
            
        except Exception as e:
            logger.error(f"Error analyzing NUMA topology: {e}")
            
        return numa_info
        
    def _parse_cpu_range(self, cpu_range: str) -> List[int]:
        """Parse CPU range string like '0-7,16-23' into list of CPU IDs."""
        cpus = []
        
        for part in cpu_range.split(','):
            if '-' in part:
                start, end = map(int, part.split('-'))
                cpus.extend(range(start, end + 1))
            else:
                cpus.append(int(part))
                
        return cpus
        
    def _check_perf_availability(self) -> bool:
        """Check if Linux perf is available for performance counters."""
        try:
            result = subprocess.run(['perf', '--version'], 
                                  capture_output=True, text=True, timeout=5)
            return result.returncode == 0
        except:
            return False
            
    def start_monitoring(self):
        """Start continuous Zen 5 workload monitoring."""
        if self.monitoring_active:
            return
            
        self.monitoring_active = True
        self.monitor_thread = threading.Thread(
            target=self._monitoring_loop,
            name="AMDZen5Monitor",
            daemon=True
        )
        self.monitor_thread.start()
        logger.info("AMD Zen 5 workload monitoring started")
        
    def stop_monitoring(self):
        """Stop continuous monitoring."""
        self.monitoring_active = False
        if self.monitor_thread and self.monitor_thread.is_alive():
            self.monitor_thread.join(timeout=5.0)
        logger.info("AMD Zen 5 workload monitoring stopped")
        
    def _monitoring_loop(self):
        """Continuous monitoring loop for Zen 5 performance."""
        while self.monitoring_active:
            try:
                # Collect performance counters
                current_counters = self._collect_zen5_performance_counters()
                if current_counters:
                    self.performance_history.append(current_counters)
                    
                # Analyze AOCL library usage
                aocl_usage = self._analyze_aocl_usage()
                if aocl_usage:
                    self.aocl_usage_history.append(aocl_usage)
                    
                # Analyze core pinning effectiveness
                self._analyze_core_pinning_effectiveness()
                
                # Update workload profiles
                self._update_workload_profiles()
                
                time.sleep(self.monitoring_interval)
                
            except Exception as e:
                logger.error(f"Error in Zen 5 monitoring loop: {e}")
                time.sleep(5.0)
                
    def _collect_zen5_performance_counters(self) -> Optional[Zen5PerformanceCounters]:
        """Collect Zen 5 architecture-specific performance counters."""
        try:
            current_time = datetime.now()
            
            # Get CPU utilization per container core set
            container_utils = self._get_container_cpu_utilization()
            
            # Get system-wide metrics
            cpu_percent = psutil.cpu_percent(interval=None)
            cpu_times = psutil.cpu_times()
            
            # Memory metrics
            memory_info = psutil.virtual_memory()
            swap_info = psutil.swap_memory()
            
            # Performance counter estimation (would be more accurate with actual perf integration)
            perf_counters = self._estimate_performance_counters()
            
            # Cache metrics estimation
            cache_metrics = self._estimate_cache_performance()
            
            # Power and thermal (estimated from available sources)
            power_thermal = self._get_power_thermal_info()
            
            # NUMA memory metrics
            numa_metrics = self._get_numa_memory_metrics()
            
            return Zen5PerformanceCounters(
                timestamp=current_time,
                llama_cpu_0_utilization=container_utils.get('llama-cpu-0', 0.0),
                llama_cpu_1_utilization=container_utils.get('llama-cpu-1', 0.0),
                llama_cpu_2_utilization=container_utils.get('llama-cpu-2', 0.0),
                system_utilization=cpu_percent,
                instructions_per_sec=perf_counters['instructions_per_sec'],
                cycles_per_sec=perf_counters['cycles_per_sec'],
                ipc=perf_counters['ipc'],
                cache_misses_per_sec=perf_counters['cache_misses_per_sec'],
                branch_mispredictions_per_sec=perf_counters['branch_mispredictions_per_sec'],
                memory_bandwidth_utilization=numa_metrics['bandwidth_utilization'],
                numa_local_access_ratio=numa_metrics['local_access_ratio'],
                memory_latency_ns=numa_metrics['latency_ns'],
                vectorized_operations_per_sec=perf_counters['vectorized_ops_per_sec'],
                aocl_library_utilization=self._get_aocl_utilization(),
                mathematical_throughput=perf_counters['math_throughput'],
                package_power_watts=power_thermal['package_power'],
                core_temperatures=power_thermal['core_temperatures'],
                power_efficiency_score=power_thermal['efficiency_score'],
                l1_cache_hit_rate=cache_metrics['l1_hit_rate'],
                l2_cache_hit_rate=cache_metrics['l2_hit_rate'],
                l3_cache_hit_rate=cache_metrics['l3_hit_rate'],
                cache_bandwidth_utilization=cache_metrics['bandwidth_utilization']
            )
            
        except Exception as e:
            logger.error(f"Error collecting Zen 5 performance counters: {e}")
            return None
            
    def _get_container_cpu_utilization(self) -> Dict[str, float]:
        """Get CPU utilization for each AI container based on core pinning."""
        container_utils = {}
        
        try:
            # Get per-CPU utilization
            per_cpu_percent = psutil.cpu_percent(percpu=True, interval=None)
            
            if len(per_cpu_percent) < self.zen5_config['total_cores']:
                # Fallback to overall CPU usage divided by containers
                overall_cpu = psutil.cpu_percent(interval=None)
                for container in self.container_cores:
                    container_utils[container] = overall_cpu / 3  # Roughly divide by 3 containers
            else:
                # Calculate utilization for each container's assigned cores
                for container, cores in self.container_cores.items():
                    if cores:
                        valid_cores = [core for core in cores if core < len(per_cpu_percent)]
                        if valid_cores:
                            container_util = sum(per_cpu_percent[core] for core in valid_cores) / len(valid_cores)
                            container_utils[container] = container_util
                        else:
                            container_utils[container] = 0.0
                    else:
                        container_utils[container] = 0.0
                        
        except Exception as e:
            logger.error(f"Error getting container CPU utilization: {e}")
            # Fallback to equal distribution
            overall_cpu = psutil.cpu_percent(interval=None)
            for container in self.container_cores:
                container_utils[container] = overall_cpu / 3
                
        return container_utils
        
    def _estimate_performance_counters(self) -> Dict[str, float]:
        """Estimate performance counters (would be more accurate with actual perf integration)."""
        counters = {
            'instructions_per_sec': 0.0,
            'cycles_per_sec': 0.0,
            'ipc': 0.0,
            'cache_misses_per_sec': 0.0,
            'branch_mispredictions_per_sec': 0.0,
            'vectorized_ops_per_sec': 0.0,
            'math_throughput': 0.0
        }
        
        try:
            cpu_percent = psutil.cpu_percent(interval=None)
            
            # Estimate based on CPU utilization and Zen 5 characteristics
            base_frequency = self.zen5_config['base_clock_ghz'] * 1e9  # Hz
            
            # Rough estimations
            counters['cycles_per_sec'] = base_frequency * (cpu_percent / 100.0)
            counters['instructions_per_sec'] = counters['cycles_per_sec'] * 2.5  # Estimated IPC for Zen 5
            counters['ipc'] = 2.5 if cpu_percent > 10 else 0.0
            
            # Cache misses and branch mispredictions (rough estimates)
            counters['cache_misses_per_sec'] = counters['instructions_per_sec'] * 0.02  # 2% miss rate
            counters['branch_mispredictions_per_sec'] = counters['instructions_per_sec'] * 0.01  # 1% mispredict
            
            # AI workload specific metrics
            counters['vectorized_ops_per_sec'] = counters['instructions_per_sec'] * 0.3  # 30% vectorized
            counters['math_throughput'] = cpu_percent * 0.8  # Arbitrary mathematical throughput metric
            
        except Exception as e:
            logger.error(f"Error estimating performance counters: {e}")
            
        return counters
        
    def _estimate_cache_performance(self) -> Dict[str, float]:
        """Estimate cache performance metrics."""
        cache_metrics = {
            'l1_hit_rate': 95.0,  # Typical L1 hit rate
            'l2_hit_rate': 85.0,  # Typical L2 hit rate
            'l3_hit_rate': 70.0,  # Typical L3 hit rate
            'bandwidth_utilization': 0.0
        }
        
        try:
            cpu_percent = psutil.cpu_percent(interval=None)
            
            # Adjust hit rates based on CPU utilization (higher utilization may reduce hit rates)
            if cpu_percent > 80:
                cache_metrics['l1_hit_rate'] -= 2.0
                cache_metrics['l2_hit_rate'] -= 5.0
                cache_metrics['l3_hit_rate'] -= 10.0
                
            # Estimate cache bandwidth utilization
            cache_metrics['bandwidth_utilization'] = min(100.0, cpu_percent * 1.2)
            
        except Exception as e:
            logger.error(f"Error estimating cache performance: {e}")
            
        return cache_metrics
        
    def _get_power_thermal_info(self) -> Dict[str, Any]:
        """Get power and thermal information."""
        power_thermal = {
            'package_power': 0.0,
            'core_temperatures': [0.0] * self.zen5_config['total_cores'],
            'efficiency_score': 0.0
        }
        
        try:
            # Try to get thermal information
            if hasattr(psutil, 'sensors_temperatures'):
                temps = psutil.sensors_temperatures()
                
                # Look for CPU temperature sensors
                for sensor_name, sensor_list in temps.items():
                    if 'cpu' in sensor_name.lower() or 'core' in sensor_name.lower():
                        for i, sensor in enumerate(sensor_list):
                            if i < len(power_thermal['core_temperatures']):
                                power_thermal['core_temperatures'][i] = sensor.current
                                
            # Estimate power consumption based on CPU utilization
            cpu_percent = psutil.cpu_percent(interval=None)
            base_power = 65.0  # Base TDP for Ryzen 9950X
            power_thermal['package_power'] = base_power + (cpu_percent / 100.0) * 105.0  # Scale to max TDP
            
            # Calculate power efficiency
            if power_thermal['package_power'] > 0:
                performance_score = cpu_percent / 100.0
                power_thermal['efficiency_score'] = performance_score / (power_thermal['package_power'] / 170.0)
            else:
                power_thermal['efficiency_score'] = 0.0
                
        except Exception as e:
            logger.error(f"Error getting power/thermal info: {e}")
            
        return power_thermal
        
    def _get_numa_memory_metrics(self) -> Dict[str, float]:
        """Get NUMA memory performance metrics."""
        numa_metrics = {
            'bandwidth_utilization': 0.0,
            'local_access_ratio': 1.0,  # Assume local access by default
            'latency_ns': 80.0  # Typical DDR5 latency
        }
        
        try:
            memory_info = psutil.virtual_memory()
            
            # Estimate memory bandwidth utilization
            if len(self.performance_history) >= 2:
                current_memory = memory_info.used
                previous_memory = getattr(self.performance_history[-1], 'memory_used', current_memory)
                
                time_delta = 1.0  # Assume 1 second interval
                memory_change = abs(current_memory - previous_memory)
                bandwidth_used_gbps = (memory_change / (1024**3)) / time_delta
                
                numa_metrics['bandwidth_utilization'] = min(100.0, 
                    (bandwidth_used_gbps / self.zen5_config['memory_bandwidth_gbps']) * 100)
            
            # NUMA locality would require more detailed analysis
            # For now, assume good locality with AI workloads
            numa_metrics['local_access_ratio'] = 0.85
            
        except Exception as e:
            logger.error(f"Error getting NUMA memory metrics: {e}")
            
        return numa_metrics
        
    def _get_aocl_utilization(self) -> float:
        """Get AOCL library utilization percentage."""
        try:
            # Check if AOCL libraries are loaded by any process
            aocl_usage = 0.0
            active_libraries = 0
            
            for proc in psutil.process_iter(['pid', 'name', 'memory_maps']):
                try:
                    if proc.info['memory_maps']:
                        for mmap in proc.info['memory_maps']:
                            for aocl_lib in self.aocl_libraries:
                                if aocl_lib in mmap.path:
                                    active_libraries += 1
                                    break
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue
                    
            # Convert to utilization percentage
            if len(self.aocl_libraries) > 0:
                aocl_usage = (active_libraries / len(self.aocl_libraries)) * 100
                
            return min(100.0, aocl_usage)
            
        except Exception as e:
            logger.error(f"Error getting AOCL utilization: {e}")
            return 0.0
            
    def _analyze_aocl_usage(self) -> Optional[AOCLLibraryUsage]:
        """Analyze AOCL library usage patterns."""
        try:
            current_time = datetime.now()
            
            library_usage = {
                'blis_operations_per_sec': 0.0,
                'lapack_operations_per_sec': 0.0,
                'fftw_operations_per_sec': 0.0,
                'scalapack_operations_per_sec': 0.0
            }
            
            # Check for AOCL library usage
            aocl_processes = []
            for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_info']):
                try:
                    if 'python' in proc.info['name'].lower():
                        # Check if this process is using AOCL libraries
                        # This would require more detailed analysis in practice
                        if proc.info['cpu_percent'] > 10:  # Active process
                            aocl_processes.append(proc.info)
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue
                    
            # Estimate AOCL performance based on active processes
            if aocl_processes:
                total_cpu = sum(proc['cpu_percent'] for proc in aocl_processes)
                
                # Rough estimation of library operations
                library_usage['blis_operations_per_sec'] = total_cpu * 1000  # Arbitrary scaling
                library_usage['lapack_operations_per_sec'] = total_cpu * 500
                
            # Determine optimization level
            optimization_level = 'none'
            performance_gain = 0.0
            
            if library_usage['blis_operations_per_sec'] > 0:
                optimization_level = 'basic'
                performance_gain = 1.2  # 20% gain estimate
                
                if library_usage['blis_operations_per_sec'] > 5000:
                    optimization_level = 'advanced'
                    performance_gain = 1.5  # 50% gain estimate
                    
            return AOCLLibraryUsage(
                blis_operations_per_sec=library_usage['blis_operations_per_sec'],
                lapack_operations_per_sec=library_usage['lapack_operations_per_sec'],
                fftw_operations_per_sec=library_usage['fftw_operations_per_sec'],
                scalapack_operations_per_sec=library_usage['scalapack_operations_per_sec'],
                optimization_level=optimization_level,
                performance_gain_estimate=performance_gain
            )
            
        except Exception as e:
            logger.error(f"Error analyzing AOCL usage: {e}")
            return None
            
    def _analyze_core_pinning_effectiveness(self):
        """Analyze effectiveness of container core pinning."""
        try:
            per_cpu_percent = psutil.cpu_percent(percpu=True, interval=None)
            
            if len(per_cpu_percent) < self.zen5_config['total_cores']:
                return
                
            for container, assigned_cores in self.container_cores.items():
                if not assigned_cores:
                    continue
                    
                # Get actual utilization of assigned cores
                actual_usage = {}
                for core in assigned_cores:
                    if core < len(per_cpu_percent):
                        actual_usage[core] = per_cpu_percent[core]
                        
                # Calculate pinning effectiveness
                if actual_usage:
                    core_utils = list(actual_usage.values())
                    avg_util = sum(core_utils) / len(core_utils)
                    util_variance = sum((util - avg_util) ** 2 for util in core_utils) / len(core_utils)
                    
                    # Effectiveness score: lower variance = better pinning
                    effectiveness = max(0.0, 1.0 - (util_variance / 1000.0))
                    
                    # Check for cross-NUMA access (simplified)
                    cross_numa_ratio = 0.0
                    if self.numa_topology['node_cpu_map']:
                        # Determine which NUMA node the assigned cores belong to
                        numa_node = None
                        for node, cpus in self.numa_topology['node_cpu_map'].items():
                            if assigned_cores[0] in cpus:
                                numa_node = node
                                break
                                
                        if numa_node is not None:
                            # Check if all cores are in the same NUMA node
                            same_numa_cores = [core for core in assigned_cores 
                                             if core in self.numa_topology['node_cpu_map'][numa_node]]
                            cross_numa_ratio = 1.0 - (len(same_numa_cores) / len(assigned_cores))
                            
                    # Performance impact assessment
                    if effectiveness > 0.8 and cross_numa_ratio < 0.1:
                        performance_impact = 'positive'
                    elif effectiveness > 0.6 and cross_numa_ratio < 0.3:
                        performance_impact = 'neutral'
                    else:
                        performance_impact = 'negative'
                        
                    # Generate recommendations
                    recommendations = []
                    if effectiveness < 0.6:
                        recommendations.append("Review container resource limits")
                        recommendations.append("Check for CPU affinity conflicts")
                    if cross_numa_ratio > 0.2:
                        recommendations.append("Optimize NUMA topology alignment")
                    if avg_util > 90:
                        recommendations.append("Consider increasing CPU allocation")
                    elif avg_util < 10:
                        recommendations.append("Consider reducing CPU allocation")
                        
                    self.core_pinning_analysis[container] = CorePinningAnalysis(
                        container_name=container,
                        assigned_cores=assigned_cores,
                        actual_core_usage=actual_usage,
                        pinning_effectiveness=effectiveness,
                        cross_numa_access_ratio=cross_numa_ratio,
                        performance_impact=performance_impact,
                        optimization_recommendations=recommendations
                    )
                    
        except Exception as e:
            logger.error(f"Error analyzing core pinning effectiveness: {e}")
            
    def _update_workload_profiles(self):
        """Update AI workload profiles based on current performance."""
        try:
            if not self.performance_history:
                return
                
            current_counters = self.performance_history[-1]
            current_time = datetime.now()
            
            # Create workload profiles for each active container
            for container, utilization in [
                ('llama-cpu-0', current_counters.llama_cpu_0_utilization),
                ('llama-cpu-1', current_counters.llama_cpu_1_utilization),
                ('llama-cpu-2', current_counters.llama_cpu_2_utilization)
            ]:
                if utilization > 10:  # Active workload
                    workload_id = f"{container}_{int(current_time.timestamp())}"
                    
                    # Classify workload characteristics
                    workload_type = self._classify_workload_type(current_counters, utilization)
                    compute_intensity = self._classify_compute_intensity(current_counters)
                    memory_pattern = self._analyze_memory_access_pattern(current_counters)
                    
                    # Calculate cache efficiency
                    cache_efficiency = (
                        current_counters.l1_cache_hit_rate * 0.5 +
                        current_counters.l2_cache_hit_rate * 0.3 +
                        current_counters.l3_cache_hit_rate * 0.2
                    ) / 100.0
                    
                    # Determine NUMA affinity
                    numa_affinity = self._determine_numa_affinity(container)
                    
                    # Calculate AOCL optimization potential
                    aocl_potential = self._calculate_aocl_potential(current_counters, workload_type)
                    
                    # Generate optimization recommendations
                    recommendations = self._generate_optimization_recommendations(
                        current_counters, container, workload_type
                    )
                    
                    profile = Zen5WorkloadProfile(
                        workload_id=workload_id,
                        workload_type=workload_type,
                        compute_intensity=compute_intensity,
                        memory_access_pattern=memory_pattern,
                        cache_efficiency=cache_efficiency,
                        numa_affinity=numa_affinity,
                        aocl_optimization_potential=aocl_potential,
                        recommended_optimizations=recommendations
                    )
                    
                    self.workload_profiles[workload_id] = profile
                    
                    # Keep only recent profiles
                    if len(self.workload_profiles) > 50:
                        oldest_key = min(self.workload_profiles.keys())
                        del self.workload_profiles[oldest_key]
                        
        except Exception as e:
            logger.error(f"Error updating workload profiles: {e}")
            
    def _classify_workload_type(self, counters: Zen5PerformanceCounters, utilization: float) -> str:
        """Classify the workload type based on performance characteristics."""
        if counters.mathematical_throughput > 60 and utilization > 70:
            return 'cpu_inference'
        elif counters.vectorized_operations_per_sec > counters.instructions_per_sec * 0.4:
            return 'mathematical'
        elif utilization > 50:
            return 'mixed'
        else:
            return 'idle'
            
    def _classify_compute_intensity(self, counters: Zen5PerformanceCounters) -> str:
        """Classify compute intensity based on instruction patterns."""
        if counters.vectorized_operations_per_sec > counters.instructions_per_sec * 0.3:
            return 'vectorized'
        elif counters.mathematical_throughput > 50:
            return 'floating_point'
        else:
            return 'integer'
            
    def _analyze_memory_access_pattern(self, counters: Zen5PerformanceCounters) -> str:
        """Analyze memory access patterns."""
        if counters.cache_misses_per_sec < counters.instructions_per_sec * 0.01:
            return 'sequential'  # Good cache performance
        elif counters.memory_bandwidth_utilization > 50:
            return 'streaming'   # High bandwidth usage
        else:
            return 'random'      # Poor cache performance
            
    def _determine_numa_affinity(self, container: str) -> int:
        """Determine preferred NUMA node for container."""
        if not self.numa_topology['node_cpu_map']:
            return 0
            
        assigned_cores = self.container_cores.get(container, [])
        if not assigned_cores:
            return 0
            
        # Find which NUMA node contains most of the assigned cores
        numa_scores = {}
        for node, cpus in self.numa_topology['node_cpu_map'].items():
            overlap = len(set(assigned_cores) & set(cpus))
            numa_scores[node] = overlap
            
        if numa_scores:
            return max(numa_scores, key=numa_scores.get)
        return 0
        
    def _calculate_aocl_potential(self, counters: Zen5PerformanceCounters, workload_type: str) -> float:
        """Calculate potential for AOCL optimization."""
        potential = 0.0
        
        if workload_type in ['cpu_inference', 'mathematical']:
            potential += 0.4  # Base potential for mathematical workloads
            
        if counters.mathematical_throughput > 50:
            potential += 0.3  # High mathematical throughput
            
        if counters.vectorized_operations_per_sec > counters.instructions_per_sec * 0.2:
            potential += 0.2  # Good vectorization
            
        if counters.aocl_library_utilization < 50:
            potential += 0.1  # Room for improvement
            
        return min(1.0, potential)
        
    def _generate_optimization_recommendations(
        self, counters: Zen5PerformanceCounters, container: str, workload_type: str
    ) -> List[str]:
        """Generate optimization recommendations for the workload."""
        recommendations = []
        
        # Cache optimization
        if counters.l3_cache_hit_rate < 60:
            recommendations.append("Optimize data locality to improve L3 cache hit rate")
            
        if counters.cache_bandwidth_utilization > 80:
            recommendations.append("Consider cache-friendly algorithms to reduce memory pressure")
            
        # AOCL optimization
        if counters.aocl_library_utilization < 30 and workload_type == 'mathematical':
            recommendations.append("Enable AOCL libraries for mathematical operations")
            
        # Memory optimization
        if counters.memory_bandwidth_utilization > 70:
            recommendations.append("Consider memory access pattern optimization")
            
        if counters.numa_local_access_ratio < 0.8:
            recommendations.append("Improve NUMA locality for memory access")
            
        # Power efficiency
        if counters.power_efficiency_score < 0.7:
            recommendations.append("Review workload for power efficiency opportunities")
            
        # Core pinning
        pinning_analysis = self.core_pinning_analysis.get(container)
        if pinning_analysis and pinning_analysis.pinning_effectiveness < 0.6:
            recommendations.append("Review CPU core pinning configuration")
            
        # IPC optimization
        if counters.ipc < 2.0:  # Below Zen 5 potential
            recommendations.append("Optimize instruction mix for better IPC")
            
        return recommendations
        
    def detect_changes(self, previous_state: SystemState) -> List[SystemChange]:
        """Detect changes in AMD Zen 5 architecture performance."""
        changes = []
        
        # Collect current performance counters
        current_counters = self._collect_zen5_performance_counters()
        if not current_counters:
            return changes
            
        # Compare with previous counters
        if self.previous_counters:
            # Container CPU utilization changes
            container_changes = [
                ('llama-cpu-0', self.previous_counters.llama_cpu_0_utilization, current_counters.llama_cpu_0_utilization),
                ('llama-cpu-1', self.previous_counters.llama_cpu_1_utilization, current_counters.llama_cpu_1_utilization),
                ('llama-cpu-2', self.previous_counters.llama_cpu_2_utilization, current_counters.llama_cpu_2_utilization)
            ]
            
            for container, prev_util, curr_util in container_changes:
                util_change = abs(curr_util - prev_util)
                if util_change > self.change_thresholds['cpu_utilization']:
                    changes.append(SystemChange(
                        component=ComponentType.CPU,
                        change_type=ChangeType.PERFORMANCE_CHANGE,
                        description=f"Zen 5 CPU utilization changed for {container}: {prev_util:.1f}% â {curr_util:.1f}%",
                        details={
                            'container': container,
                            'previous_utilization': prev_util,
                            'current_utilization': curr_util,
                            'assigned_cores': self.container_cores.get(container, []),
                            'architecture': 'Zen 5'
                        },
                        significance=self._determine_cpu_significance(util_change),
                        timestamp=current_counters.timestamp
                    ))
                    
            # IPC (Instructions Per Cycle) changes
            ipc_change = abs(current_counters.ipc - self.previous_counters.ipc)
            if ipc_change > self.change_thresholds['ipc_change']:
                changes.append(SystemChange(
                    component=ComponentType.CPU,
                    change_type=ChangeType.PERFORMANCE_CHANGE,
                    description=f"Zen 5 IPC changed: {self.previous_counters.ipc:.2f} â {current_counters.ipc:.2f}",
                    details={
                        'previous_ipc': self.previous_counters.ipc,
                        'current_ipc': current_counters.ipc,
                        'instructions_per_sec': current_counters.instructions_per_sec,
                        'cycles_per_sec': current_counters.cycles_per_sec,
                        'optimization_potential': current_counters.ipc < 2.5
                    },
                    significance=Significance.MEDIUM if current_counters.ipc < 2.0 else Significance.LOW,
                    timestamp=current_counters.timestamp
                ))
                
            # Memory bandwidth changes
            memory_bw_change = abs(current_counters.memory_bandwidth_utilization - 
                                 self.previous_counters.memory_bandwidth_utilization)
            if memory_bw_change > self.change_thresholds['memory_bandwidth']:
                changes.append(SystemChange(
                    component=ComponentType.MEMORY,
                    change_type=ChangeType.RESOURCE_CHANGE,
                    description=f"DDR5 memory bandwidth utilization changed by {memory_bw_change:.1f}%: {current_counters.memory_bandwidth_utilization:.1f}%",
                    details={
                        'previous_bandwidth_util': self.previous_counters.memory_bandwidth_utilization,
                        'current_bandwidth_util': current_counters.memory_bandwidth_utilization,
                        'numa_local_access_ratio': current_counters.numa_local_access_ratio,
                        'memory_latency_ns': current_counters.memory_latency_ns,
                        'memory_type': 'DDR5-6000'
                    },
                    significance=self._determine_memory_significance(current_counters.memory_bandwidth_utilization),
                    timestamp=current_counters.timestamp
                ))
                
            # Cache performance changes
            cache_changes = [
                ('L1', self.previous_counters.l1_cache_hit_rate, current_counters.l1_cache_hit_rate),
                ('L2', self.previous_counters.l2_cache_hit_rate, current_counters.l2_cache_hit_rate),
                ('L3', self.previous_counters.l3_cache_hit_rate, current_counters.l3_cache_hit_rate)
            ]
            
            for cache_level, prev_rate, curr_rate in cache_changes:
                rate_change = abs(curr_rate - prev_rate)
                if rate_change > self.change_thresholds['cache_hit_rate']:
                    changes.append(SystemChange(
                        component=ComponentType.CACHE,
                        change_type=ChangeType.PERFORMANCE_CHANGE,
                        description=f"Zen 5 {cache_level} cache hit rate changed: {prev_rate:.1f}% â {curr_rate:.1f}%",
                        details={
                            'cache_level': cache_level,
                            'previous_hit_rate': prev_rate,
                            'current_hit_rate': curr_rate,
                            'cache_bandwidth_util': current_counters.cache_bandwidth_utilization,
                            'performance_impact': 'negative' if curr_rate < prev_rate else 'positive'
                        },
                        significance=self._determine_cache_significance(cache_level, curr_rate),
                        timestamp=current_counters.timestamp
                    ))
                    
            # AOCL utilization changes
            aocl_change = abs(current_counters.aocl_library_utilization - 
                            self.previous_counters.aocl_library_utilization)
            if aocl_change > self.change_thresholds['aocl_utilization']:
                changes.append(SystemChange(
                    component=ComponentType.AI_OPTIMIZATION,
                    change_type=ChangeType.OPTIMIZATION_CHANGE,
                    description=f"AOCL library utilization changed by {aocl_change:.1f}%: {current_counters.aocl_library_utilization:.1f}%",
                    details={
                        'previous_aocl_utilization': self.previous_counters.aocl_library_utilization,
                        'current_aocl_utilization': current_counters.aocl_library_utilization,
                        'mathematical_throughput': current_counters.mathematical_throughput,
                        'vectorized_operations': current_counters.vectorized_operations_per_sec,
                        'optimization_opportunity': current_counters.aocl_library_utilization < 50
                    },
                    significance=Significance.MEDIUM,
                    timestamp=current_counters.timestamp
                ))
                
            # Power efficiency changes
            efficiency_change = abs(current_counters.power_efficiency_score - 
                                  self.previous_counters.power_efficiency_score)
            if efficiency_change > 0.2:
                changes.append(SystemChange(
                    component=ComponentType.POWER,
                    change_type=ChangeType.EFFICIENCY_CHANGE,
                    description=f"Zen 5 power efficiency changed: {self.previous_counters.power_efficiency_score:.2f} â {current_counters.power_efficiency_score:.2f}",
                    details={
                        'previous_efficiency': self.previous_counters.power_efficiency_score,
                        'current_efficiency': current_counters.power_efficiency_score,
                        'package_power': current_counters.package_power_watts,
                        'core_temperatures': current_counters.core_temperatures,
                        'system_utilization': current_counters.system_utilization
                    },
                    significance=Significance.MEDIUM if current_counters.power_efficiency_score < 0.7 else Significance.LOW,
                    timestamp=current_counters.timestamp
                ))
                
        # Store current counters for next comparison
        self.previous_counters = current_counters
        
        return changes
        
    def _determine_cpu_significance(self, utilization_change: float) -> Significance:
        """Determine significance of CPU utilization changes."""
        if utilization_change > 40:
            return Significance.HIGH
        elif utilization_change > 20:
            return Significance.MEDIUM
        else:
            return Significance.LOW
            
    def _determine_memory_significance(self, bandwidth_utilization: float) -> Significance:
        """Determine significance of memory bandwidth changes."""
        if bandwidth_utilization > 80:
            return Significance.HIGH
        elif bandwidth_utilization > 50:
            return Significance.MEDIUM
        else:
            return Significance.LOW
            
    def _determine_cache_significance(self, cache_level: str, hit_rate: float) -> Significance:
        """Determine significance of cache performance changes."""
        if cache_level == 'L1' and hit_rate < 90:
            return Significance.HIGH
        elif cache_level == 'L2' and hit_rate < 80:
            return Significance.HIGH
        elif cache_level == 'L3' and hit_rate < 60:
            return Significance.HIGH
        elif hit_rate < 70:
            return Significance.MEDIUM
        else:
            return Significance.LOW
            
    def get_zen5_status_summary(self) -> Dict[str, Any]:
        """Get comprehensive Zen 5 status summary."""
        if not self.performance_history:
            current_counters = self._collect_zen5_performance_counters()
        else:
            current_counters = self.performance_history[-1]
            
        if not current_counters:
            return {'status': 'unavailable', 'reason': 'Cannot collect performance counters'}
            
        # Get latest AOCL usage
        latest_aocl = None
        if self.aocl_usage_history:
            latest_aocl = self.aocl_usage_history[-1]
            
        # Get recent workload profiles
        recent_profiles = list(self.workload_profiles.values())[-3:] if self.workload_profiles else []
        
        return {
            'status': 'active',
            'architecture': 'Zen 5',
            'cpu_model': self.zen5_config['cpu_model'],
            'is_zen5_verified': self.cpu_info['is_zen5'],
            'current_performance': {
                'system_utilization': current_counters.system_utilization,
                'container_utilization': {
                    'llama-cpu-0': current_counters.llama_cpu_0_utilization,
                    'llama-cpu-1': current_counters.llama_cpu_1_utilization,
                    'llama-cpu-2': current_counters.llama_cpu_2_utilization
                },
                'ipc': current_counters.ipc,
                'mathematical_throughput': current_counters.mathematical_throughput,
                'vectorized_operations_per_sec': current_counters.vectorized_operations_per_sec
            },
            'memory_performance': {
                'bandwidth_utilization': current_counters.memory_bandwidth_utilization,
                'numa_local_access_ratio': current_counters.numa_local_access_ratio,
                'memory_latency_ns': current_counters.memory_latency_ns,
                'memory_type': self.zen5_config['memory_type']
            },
            'cache_performance': {
                'l1_hit_rate': current_counters.l1_cache_hit_rate,
                'l2_hit_rate': current_counters.l2_cache_hit_rate,
                'l3_hit_rate': current_counters.l3_cache_hit_rate,
                'cache_bandwidth_utilization': current_counters.cache_bandwidth_utilization
            },
            'aocl_optimization': {
                'library_utilization': current_counters.aocl_library_utilization,
                'optimization_level': latest_aocl.optimization_level if latest_aocl else 'unknown',
                'performance_gain': latest_aocl.performance_gain_estimate if latest_aocl else 0.0,
                'blis_operations_per_sec': latest_aocl.blis_operations_per_sec if latest_aocl else 0.0
            },
            'power_thermal': {
                'package_power_watts': current_counters.package_power_watts,
                'efficiency_score': current_counters.power_efficiency_score,
                'core_temperatures': current_counters.core_temperatures,
                'thermal_status': 'normal' if max(current_counters.core_temperatures, default=0) < 80 else 'elevated'
            },
            'core_pinning': {
                'container_assignments': self.container_cores,
                'pinning_analysis': {
                    name: {
                        'effectiveness': analysis.pinning_effectiveness,
                        'performance_impact': analysis.performance_impact,
                        'recommendations': analysis.optimization_recommendations
                    }
                    for name, analysis in self.core_pinning_analysis.items()
                }
            },
            'numa_topology': {
                'nodes': self.numa_topology['nodes'],
                'cpu_mapping': self.numa_topology['node_cpu_map']
            },
            'recent_workloads': [
                {
                    'workload_type': profile.workload_type,
                    'compute_intensity': profile.compute_intensity,
                    'cache_efficiency': profile.cache_efficiency,
                    'aocl_potential': profile.aocl_optimization_potential,
                    'recommendations': profile.recommended_optimizations
                }
                for profile in recent_profiles
            ],
            'monitoring_stats': {
                'performance_samples': len(self.performance_history),
                'aocl_samples': len(self.aocl_usage_history),
                'workload_profiles': len(self.workload_profiles),
                'monitoring_active': self.monitoring_active,
                'last_update': current_counters.timestamp.isoformat()
            }
        }
        
    def __del__(self):
        """Cleanup on object destruction."""
        try:
            self.stop_monitoring()
        except Exception:
            pass